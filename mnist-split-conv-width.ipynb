{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a, n_classes):\n",
    "    return np.squeeze(np.eye(n_classes)[a.reshape(-1)])\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "#y_train = one_hot(y_train, 10)\n",
    "#y_test = one_hot(y_test, 10)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        l = tf.keras.layers\n",
    "        self.pool = l.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
    "        self.conv1 = l.Conv2D(32, 5, padding='SAME', activation=tf.nn.relu)\n",
    "        self.conv2 = l.Conv2D(64, 5, padding='SAME', activation=tf.nn.relu)\n",
    "        self.flatten = l.Flatten()\n",
    "        self.dropout = l.Dropout(0.4)\n",
    "        self.dense1 = l.Dense(1024, activation=tf.nn.relu)\n",
    "        self.dense2 = l.Dense(10, activation=tf.nn.softmax)\n",
    "        \n",
    "        layers = [self.pool, self.conv1, self.conv2, self.flatten, self.dropout, self.dense1, self.dense2]\n",
    "        self.trainable_variables = [v for v in (layer.trainable_variables for layer in layers)]\n",
    "        \n",
    "        self.optimizer = tf.optimizers.Adam()\n",
    "        self.loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        self.batch_size = 128\n",
    "\n",
    "    def build(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def train(self, dataset, epochs):\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        for epoch in range(epochs):\n",
    "            print(f'[Epoch {epoch+1}/{epochs}]')\n",
    "            epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "            epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "            \n",
    "            progress = tqdm(total=X_train.shape[0], unit='samples')\n",
    "            for x, y in dataset:\n",
    "                progress.update(self.batch_size)\n",
    "                preds = self.forward(x)\n",
    "                loss = lambda: self.loss_function(y_true=y, y_pred=preds)\n",
    "                #grads = tape.gradient(loss, self.trainable_variables)\n",
    "                self.optimizer.minimize(loss, self.trainable_variables)\n",
    "                epoch_loss_avg(loss())\n",
    "                epoch_accuracy(y, preds)\n",
    "            print(f'Loss: {epoch_loss_avg.result():.4f}, Accuracy: {epoch_accuracy.result():.2%}')\n",
    "            print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(split_convolutions=False):\n",
    "    l = tf.keras.layers\n",
    "    \n",
    "    inputs = l.Input(shape=(28, 28, 1))\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.random.normal([5, 5, 1, 32])),\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'bc1': tf.Variable(tf.random.normal([32]))\n",
    "    }\n",
    "    \n",
    "    \n",
    "    x = inputs\n",
    "    if split_convolutions:\n",
    "        x1, x2 = tf.split(x, 2, axis=1)\n",
    "        x1 = tf.nn.conv2d(x1, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "        x1 = tf.nn.bias_add(x1, biases['bc1'])\n",
    "        x2 = tf.nn.conv2d(x2, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "        x2 = tf.nn.bias_add(x2, biases['bc1'])\n",
    "        x = tf.concat([x1, x2], axis=1)\n",
    "    else:\n",
    "        #x = l.Conv2D(32, 5, padding='SAME', activation=tf.nn.relu)(x)\n",
    "        x = tf.nn.conv2d(x, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, biases['bc1'])\n",
    "    \n",
    "    x = tf.nn.max_pool(x, (2, 2), (2, 2), 'SAME')\n",
    "    x = l.Conv2D(64, 5, padding='SAME', activation=tf.nn.relu)(x)\n",
    "    x = tf.nn.max_pool(x, (2, 2), (2, 2), 'SAME')\n",
    "    x = l.Flatten()(x)\n",
    "    x = l.Dense(1024, activation=tf.nn.relu)(x)\n",
    "    x = tf.nn.dropout(x, 0.4)\n",
    "    x = l.Dense(10, activation=tf.nn.softmax)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 468 steps\n",
      "Epoch 1/5\n",
      "468/468 [==============================] - 36s 77ms/step - loss: 0.2489 - accuracy: 0.9391\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 37s 79ms/step - loss: 0.0655 - accuracy: 0.9794\n",
      "Epoch 3/5\n",
      "449/468 [===========================>..] - ETA: 1s - loss: 0.0505 - accuracy: 0.9841"
     ]
    }
   ],
   "source": [
    "model = build_model(True)\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset.shuffle(10000).repeat(5).batch(128), epochs=5, steps_per_epoch=X_train.shape[0] // 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
